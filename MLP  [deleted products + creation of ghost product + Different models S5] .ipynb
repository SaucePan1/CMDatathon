{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP \n",
    "\n",
    "We have considered adequated to treat this problem as natural language processing is normally treated. We have sequences of words that behave according to hidden grammar rules that the MLP has to learn in order the predict what word comes next. (Analogous to having a sequence of products that behave according to hidden market rules we need to learn in order to predict what product comes next).\n",
    "\n",
    "Our training set can be made up of ALL the users, but we will 'hide' the last product they have purchased. That is \n",
    "\n",
    "- X_train = Sequence of products all users bought but the last one. 80%\n",
    "- y_train = target we need to predict, that will be the last product they've purchased. 80%\n",
    "\n",
    "- X_test = Sequence of all products but the last one 20%\n",
    "- y_test = Last product this 20% have bought.\n",
    "\n",
    "**Remarks:**\n",
    "\n",
    "- We can add these 20% to the X_train (we shall give the sequence of the purchased products but the last two.) and add the 'penultimo' to the y_train.\n",
    "\n",
    "- We can multiply the training set by transforming the sequence of products 'abcde' to 'ab' 'abc' 'abcd' 'abcde'. (Is it a good idea? It seems ok to me, why ? Test what is better.\n",
    "\n",
    "- We can add the test.txt to the training set without no problem. (Yes, no?)\n",
    "\n",
    "- We MUST delete users with only one product, they have no training value. We can use to test but eh. I would just delete them.\n",
    "\n",
    "- Do some kind of selection of the 'best' users to train the net?\n",
    "\n",
    "- We are not using the Socio_Demo features, it would be nice to treat them with another approach and then combine the two.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the data\n",
    "dftrain = pd.read_csv('train2-2.txt', sep='|')\n",
    "dftest = pd.read_csv('test2.txt', sep= '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Customer</th>\n",
       "      <th>Cod_Prod</th>\n",
       "      <th>Cod_Fecha</th>\n",
       "      <th>Socio_Demo_01</th>\n",
       "      <th>Socio_Demo_02</th>\n",
       "      <th>Socio_Demo_03</th>\n",
       "      <th>Socio_Demo_04</th>\n",
       "      <th>Socio_Demo_05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>601</td>\n",
       "      <td>2007-05</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>704</td>\n",
       "      <td>2013-04</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>2501</td>\n",
       "      <td>2006-03</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>2503</td>\n",
       "      <td>2006-03</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>1011</td>\n",
       "      <td>2011-04</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0000002</td>\n",
       "      <td>601</td>\n",
       "      <td>1998-06</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A0000002</td>\n",
       "      <td>801</td>\n",
       "      <td>2006-02</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_Customer  Cod_Prod Cod_Fecha  Socio_Demo_01  Socio_Demo_02  \\\n",
       "0    A0000001       601   2007-05              5              4   \n",
       "1    A0000001       704   2013-04              5              4   \n",
       "2    A0000001      2501   2006-03              5              4   \n",
       "3    A0000001      2503   2006-03              5              4   \n",
       "4    A0000001      1011   2011-04              5              4   \n",
       "5    A0000002       601   1998-06              5              5   \n",
       "6    A0000002       801   2006-02              5              5   \n",
       "\n",
       "   Socio_Demo_03  Socio_Demo_04  Socio_Demo_05  \n",
       "0              3              1              0  \n",
       "1              3              1              0  \n",
       "2              3              1              0  \n",
       "3              3              1              0  \n",
       "4              3              1              0  \n",
       "5              1              1              0  \n",
       "6              1              1              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftrain.drop('Socio_Demo_04', axis= 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As argued we directly delete the feature gender for etical reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Customer</th>\n",
       "      <th>Cod_Prod</th>\n",
       "      <th>Cod_Fecha</th>\n",
       "      <th>Socio_Demo_01</th>\n",
       "      <th>Socio_Demo_02</th>\n",
       "      <th>Socio_Demo_03</th>\n",
       "      <th>Socio_Demo_05</th>\n",
       "      <th>Prod_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>601</td>\n",
       "      <td>2007-05</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>704</td>\n",
       "      <td>2013-04</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>2501</td>\n",
       "      <td>2006-03</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>2503</td>\n",
       "      <td>2006-03</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>1011</td>\n",
       "      <td>2011-04</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0000002</td>\n",
       "      <td>601</td>\n",
       "      <td>1998-06</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_Customer  Cod_Prod Cod_Fecha  Socio_Demo_01  Socio_Demo_02  \\\n",
       "0    A0000001       601   2007-05              5              4   \n",
       "1    A0000001       704   2013-04              5              4   \n",
       "2    A0000001      2501   2006-03              5              4   \n",
       "3    A0000001      2503   2006-03              5              4   \n",
       "4    A0000001      1011   2011-04              5              4   \n",
       "5    A0000002       601   1998-06              5              5   \n",
       "\n",
       "   Socio_Demo_03  Socio_Demo_05  Prod_int  \n",
       "0              3              0         0  \n",
       "1              3              0         0  \n",
       "2              3              0         0  \n",
       "3              3              0         0  \n",
       "4              3              0         0  \n",
       "5              1              0         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain['Prod_int'] = np.zeros(dftrain.ID_Customer.size, dtype=int)\n",
    "dftrain.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  filter the data, deleting products that have low sells. We have tried three cases, 100, 300 and 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        94.000000\n",
       "mean      35644.691489\n",
       "std       96394.340067\n",
       "min           1.000000\n",
       "25%         364.250000\n",
       "50%        3205.500000\n",
       "75%       15433.500000\n",
       "max      661756.000000\n",
       "Name: ID_Customer, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sells_per_product = dftrain.groupby('Cod_Prod').ID_Customer.count()\n",
    "Sells_per_product.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have previously commented when exploring the data there is a vast ammount of products with close to no sells compared to the 'best sellers', that is clearly reflected on the high variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16,) (23,) (43,)\n",
      "Percentage of sells that we are droping: 0.01128%, 0.05492%, 0.78246%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 101,  104,  502,  504,  703,  803,  804, 1004, 1005, 1006, 1008,\n",
       "       1010, 1014, 1015, 1305, 1308, 1312, 1803, 1806, 2104, 2502, 2801,\n",
       "       2901])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explore the effect that will have deleting low selling products.\n",
    "\n",
    "products_sub100 = Sells_per_product[Sells_per_product <100].index.values\n",
    "products_sub300 = Sells_per_product[Sells_per_product < 300].index.values\n",
    "products_sub2500 = Sells_per_product[Sells_per_product <2500].index.values\n",
    "print products_sub100.shape, products_sub300.shape , products_sub2500.shape\n",
    "a = Sells_per_product[Sells_per_product <100].sum()/float(Sells_per_product.sum())*100\n",
    "b = Sells_per_product[Sells_per_product <300].sum()/float(Sells_per_product.sum())*100\n",
    "c = Sells_per_product[Sells_per_product <2500].sum()/float(Sells_per_product.sum())*100\n",
    "print 'Percentage of sells that we are droping: {0:.5f}%, {1:.5f}%, {2:.5f}%'.format(a, b, c)\n",
    "products_sub300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any case we are dropping less than 1% of the sells, so we expect our accuracy to not be affected by more than 1% by this simplifications. Given the vast ammount of data and supposing the test and the train where created under the same conditions this is a safe assumption to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Filter the data in three groups.\n",
    "#We delete rare products\n",
    "df100 = dftrain.query('Cod_Prod not in @products_sub100')\n",
    "df300 = dftrain.query('Cod_Prod not in @products_sub300')\n",
    "df2500 = dftrain.query('Cod_Prod not in @products_sub2500')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have done diferent tests and achived the best results dropping all the products sub2500. From now on we shall only work with these data.\n",
    "\n",
    "Now we have to prepare the data we will feed to the MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data set and drop users that only bought one product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clean the datafram of useless users. \n",
    "#Users that have only bought one product and thus will be useless for the MLP\n",
    "\n",
    "def users_one_buy_clean(df):\n",
    "    \"\"\"\n",
    "    Cleans the data frame from users that have only bought one product.\n",
    "    Returns dataframe\n",
    "    \"\"\"\n",
    "    dropusers = df.groupby('ID_Customer')['Cod_Prod'].count()\n",
    "    dropusers = dropusers[dropusers == 1]\n",
    "    users_to_drop= dropusers.index\n",
    "    filtered_df = df.query('ID_Customer not in @users_to_drop')\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2500 = users_one_buy_clean(df2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have argued clients with diferent Socio_Demo_5 will probably be interested in diferent products. So training a diferent MLP for each S5 seems like a good bet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Divide the data between different S5 values\n",
    "#We split the data set into subcategories acording to its S5\n",
    "\n",
    "df2500_0 = df2500.query('Socio_Demo_05 == 0')\n",
    "df2500_1 = df2500.query('Socio_Demo_05 == 1')\n",
    "df2500_2 = df2500.query('Socio_Demo_05 == 2')\n",
    "df2500_3 = df2500.query('Socio_Demo_05 == 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Customer</th>\n",
       "      <th>Cod_Prod</th>\n",
       "      <th>Cod_Fecha</th>\n",
       "      <th>Socio_Demo_01</th>\n",
       "      <th>Socio_Demo_02</th>\n",
       "      <th>Socio_Demo_03</th>\n",
       "      <th>Socio_Demo_05</th>\n",
       "      <th>Prod_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>601</td>\n",
       "      <td>2007-05</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>704</td>\n",
       "      <td>2013-04</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>2501</td>\n",
       "      <td>2006-03</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>2503</td>\n",
       "      <td>2006-03</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>1011</td>\n",
       "      <td>2011-04</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0000002</td>\n",
       "      <td>601</td>\n",
       "      <td>1998-06</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A0000002</td>\n",
       "      <td>801</td>\n",
       "      <td>2006-02</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0000002</td>\n",
       "      <td>9992</td>\n",
       "      <td>2015-02</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A0000002</td>\n",
       "      <td>301</td>\n",
       "      <td>1995-03</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A0000003</td>\n",
       "      <td>601</td>\n",
       "      <td>1985-11</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_Customer  Cod_Prod Cod_Fecha  Socio_Demo_01  Socio_Demo_02  \\\n",
       "0    A0000001       601   2007-05              5              4   \n",
       "1    A0000001       704   2013-04              5              4   \n",
       "2    A0000001      2501   2006-03              5              4   \n",
       "3    A0000001      2503   2006-03              5              4   \n",
       "4    A0000001      1011   2011-04              5              4   \n",
       "5    A0000002       601   1998-06              5              5   \n",
       "6    A0000002       801   2006-02              5              5   \n",
       "7    A0000002      9992   2015-02              5              5   \n",
       "8    A0000002       301   1995-03              5              5   \n",
       "9    A0000003       601   1985-11              5              5   \n",
       "\n",
       "   Socio_Demo_03  Socio_Demo_05  Prod_int  \n",
       "0              3              0         0  \n",
       "1              3              0         0  \n",
       "2              3              0         0  \n",
       "3              3              0         0  \n",
       "4              3              0         0  \n",
       "5              1              0         0  \n",
       "6              1              0         0  \n",
       "7              1              0         0  \n",
       "8              1              0         0  \n",
       "9              5              0         0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2500_0.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a ghost product.\n",
    "\n",
    "This ghost product will tell our model the '1990-01' mark, the year after most products started to be aviable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fecha = '1990-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creation of the ghost product\n",
    "\n",
    "def ghost_product(data, fecha):\n",
    "    \n",
    "    '''\n",
    "    Adds a the ghost product to every user. Returns a data frame \n",
    "    '''\n",
    "\n",
    "    customers = data.ID_Customer.unique()\n",
    "\n",
    "    #Create a df with the ghost product following the required shape\n",
    "    \n",
    "    df_fecha_total_prod = pd.DataFrame(np.zeros((customers.size, data.columns.size), dtype = int), columns= data.columns)\n",
    "    df_fecha_total_prod['Cod_Fecha']= fecha\n",
    "    df_fecha_total_prod.Cod_Prod = 1\n",
    "    df_fecha_total_prod.ID_Customer = customers\n",
    "    #Concatenate with the original dataframe and order by customer\n",
    "    df_fecha_total_prod.index = range(data.index.size , data.index.size + customers.size, 1)\n",
    "    new_df = pd.concat([df_fecha_total_prod, data])\n",
    "    new_df.sort_values('ID_Customer', inplace = True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2500_0 = ghost_product(df2500_0, fecha)\n",
    "df2500_1 = ghost_product(df2500_1, fecha)\n",
    "df2500_2 = ghost_product(df2500_2, fecha)\n",
    "df2500_3 = ghost_product(df2500_3, fecha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** NOW WE HAVE TO SET THE INT ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prod_int_fill(df):\n",
    "    \"\"\"\n",
    "    takes dataframe and returns with the cloumns Prod_int filled\n",
    "    \"\"\"\n",
    "#Fill the column of Prod_int, this will be the labels the mlp will work with\n",
    "#We will save the identificator '0' to indicate 'no purchase'. This will become clear when designing the MLP\n",
    "\n",
    "    products=df.Cod_Prod.unique()\n",
    "    products=np.sort(products)\n",
    "    for i in range(products.size):\n",
    "        df.loc[df['Cod_Prod'] == products[i], 'Prod_int'] = i+1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Customer</th>\n",
       "      <th>Cod_Prod</th>\n",
       "      <th>Cod_Fecha</th>\n",
       "      <th>Socio_Demo_01</th>\n",
       "      <th>Socio_Demo_02</th>\n",
       "      <th>Socio_Demo_03</th>\n",
       "      <th>Socio_Demo_05</th>\n",
       "      <th>Prod_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2569763</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>1990-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>2501</td>\n",
       "      <td>2006-03</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>2503</td>\n",
       "      <td>2006-03</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>1011</td>\n",
       "      <td>2011-04</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>704</td>\n",
       "      <td>2013-04</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID_Customer  Cod_Prod Cod_Fecha  Socio_Demo_01  Socio_Demo_02  \\\n",
       "2569763    A0000001         1   1990-01              0              0   \n",
       "2          A0000001      2501   2006-03              5              4   \n",
       "3          A0000001      2503   2006-03              5              4   \n",
       "4          A0000001      1011   2011-04              5              4   \n",
       "1          A0000001       704   2013-04              5              4   \n",
       "\n",
       "         Socio_Demo_03  Socio_Demo_05  Prod_int  \n",
       "2569763              0              0         1  \n",
       "2                    3              0        38  \n",
       "3                    3              0        39  \n",
       "4                    3              0        16  \n",
       "1                    3              0         8  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2500_0 = prod_int_fill(df2500_0)\n",
    "df2500_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have treated the data: deleted low selling products, deleted users with only one buy, split taking into account S5 and added  variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Cod_Prod, dtype: int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets run a couple of tests to see everything is OK.\n",
    "buys_per_customer = df2500_0.groupby('ID_Customer')['Cod_Prod'].count()\n",
    "buys_per_customer[buys_per_customer <=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "#Should be equal. We started setting ints at 1! Not 0!\n",
    "print df2500_0.Cod_Prod.unique().size\n",
    "print np.max(df2500_0.Prod_int.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Divide the clients in training and test\n",
    "\n",
    "def train_test(df, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Divides the data randomly into train and test by users returns (df_train , df_test)\n",
    "    df: data to split\n",
    "    test_size: size in % of the test. default 0.2.\n",
    "    \"\"\"\n",
    "    Validusers= df['ID_Customer'].unique()\n",
    "    users_for_test = np.random.choice(Validusers, size= int(len(Validusers)*test_size), replace= False)\n",
    "    data_test = df.query('ID_Customer in @users_for_test')\n",
    "    data_train = df.query('ID_Customer not in @users_for_test')\n",
    "    print 'Users for test: ', data_test.shape\n",
    "    print 'Users for train: ', data_train.shape\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users for test:  (614112, 8)\n",
      "Users for train:  (2460042, 8)\n"
     ]
    }
   ],
   "source": [
    "## Split into test train\n",
    "\n",
    "train_0_2500, test_0_2500 = train_test(df2500_0)\n",
    "#train_1_2500, test_1_2500 = train_test(df2500_1)\n",
    "#train_2_2500, test_2_2500 = train_test(df2500_2)\n",
    "#train_3_2500, test_3_2500 = train_test(df2500_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_Customer</th>\n",
       "      <th>Cod_Prod</th>\n",
       "      <th>Cod_Fecha</th>\n",
       "      <th>Socio_Demo_01</th>\n",
       "      <th>Socio_Demo_02</th>\n",
       "      <th>Socio_Demo_03</th>\n",
       "      <th>Socio_Demo_05</th>\n",
       "      <th>Prod_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2569763</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>1990-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>2501</td>\n",
       "      <td>2006-03</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>2503</td>\n",
       "      <td>2006-03</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>1011</td>\n",
       "      <td>2011-04</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0000001</td>\n",
       "      <td>704</td>\n",
       "      <td>2013-04</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID_Customer  Cod_Prod Cod_Fecha  Socio_Demo_01  Socio_Demo_02  \\\n",
       "2569763    A0000001         1   1990-01              0              0   \n",
       "2          A0000001      2501   2006-03              5              4   \n",
       "3          A0000001      2503   2006-03              5              4   \n",
       "4          A0000001      1011   2011-04              5              4   \n",
       "1          A0000001       704   2013-04              5              4   \n",
       "\n",
       "         Socio_Demo_03  Socio_Demo_05  Prod_int  \n",
       "2569763              0              0         1  \n",
       "2                    3              0        38  \n",
       "3                    3              0        39  \n",
       "4                    3              0        16  \n",
       "1                    3              0         8  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0_2500.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A partir de aqui solo has continuado con train_0_2500 y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID_Customer  Prod_int\n",
       "A0000001     1           1990-01\n",
       "             6           2007-05\n",
       "             8           2013-04\n",
       "             16          2011-04\n",
       "             38          2006-03\n",
       "             39          2006-03\n",
       "Name: Cod_Fecha, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the purhcase history of every customer\n",
    "historial_users_train_0_2500=train_0_2500.groupby(['ID_Customer', 'Prod_int'])['Cod_Fecha'].first()\n",
    "historial_users_test_0_2500=test_0_2500.groupby(['ID_Customer', 'Prod_int'])['Cod_Fecha'].first()\n",
    "historial_users_train_0_2500.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sort by fecha and convert indices to a sequences of list\n",
    "\n",
    "historial_users_train_0_2500.sort_values(inplace = True)\n",
    "historial_users_test_0_2500.sort_values(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We extract the list of products with the most recent one in the last position. We convert them to lists.\n",
    "X_train = historial_users_train_0_2500.reset_index().groupby('ID_Customer')['Prod_int'].apply(np.array).values.tolist()\n",
    "X_test = historial_users_test_0_2500.reset_index().groupby('ID_Customer')['Prod_int'].apply(np.array).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1, 39, 38,  6, 16,  8]),\n",
       " array([ 1,  4,  6, 12, 51]),\n",
       " array([ 6,  1, 39, 38,  4,  3]),\n",
       " array([ 1,  6,  4,  3, 35]),\n",
       " array([4, 6, 1]),\n",
       " array([ 1,  4, 52, 50, 33,  6, 36]),\n",
       " array([ 1, 36, 52, 50,  6,  4, 16, 33,  8])]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we have to delete the last products in order to produce the output and the input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dividimos entre X_train i y_train # SOLO EJECUTAR UNA VEZ BORRA COSAS\n",
    "#Copy the last product to the target and then delete\n",
    "\n",
    "X_traindel= np.copy(X_train)\n",
    "X_testdel = np.copy(X_test)\n",
    "y_train=np.zeros(len(X_train), dtype=int)\n",
    "y_test=np.zeros(len(X_test), dtype=int)\n",
    "\n",
    "i=0\n",
    "for hist in X_train:\n",
    "    if hist[-1:] != 1:\n",
    "        y_train[i]=hist[-1:]\n",
    "        X_traindel[i]= np.delete(X_traindel[i], X_traindel[i].size-1)\n",
    "    else:\n",
    "    #If the last product is the ghost product 1990 then we assign the preceding and delete two\n",
    "        y_train[i]=hist[-2:-1]\n",
    "        X_traindel[i]= np.delete(X_traindel[i], X_traindel[i].size-1)\n",
    "        X_traindel[i]= np.delete(X_traindel[i], X_traindel[i].size-1) #Delete two times the last one ! So the last two\n",
    "    i=i+1\n",
    "i=0\n",
    "for hist in X_test:\n",
    "    if hist[-1:] != 1: #Prod_int ghost = 1\n",
    "        y_test[i]=hist[-1:]\n",
    "        X_testdel[i]= np.delete(X_test[i], X_test[i].size-1)\n",
    "    else:\n",
    "    #If the last product is the ghost product 1990 then we assign the preceding and delete two\n",
    "        y_test[i]=hist[-2:-1]\n",
    "        X_testdel[i]= np.delete(X_testdel[i], X_testdel[i].size-1)\n",
    "        X_testdel[i]= np.delete(X_testdel[i], X_testdel[i].size-1)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1, 39, 38,  6, 16,  8]),\n",
       " array([ 1,  4,  6, 12, 51]),\n",
       " array([ 6,  1, 39, 38,  4,  3]),\n",
       " array([ 1,  6,  4,  3, 35]),\n",
       " array([4, 6, 1]),\n",
       " array([ 1,  4, 52, 50, 33,  6, 36]),\n",
       " array([ 1, 36, 52, 50,  6,  4, 16, 33,  8])]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 1, 39, 38,  6, 16]) array([ 1,  4,  6, 12])\n",
      " array([ 6,  1, 39, 38,  4]) array([1, 6, 4, 3]) array([4])]\n",
      "[ 8 51  3 35  6]\n"
     ]
    }
   ],
   "source": [
    "print X_traindel[:5]\n",
    "print y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is ok!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historial Usuario (en Train):  75744\n",
      "[ 1  4 52 50  6]\n",
      "6\n",
      "[ 1  4 52 50]\n",
      "Historial Usuario (en Train):  29456\n",
      "[4 6 1]\n",
      "6\n",
      "[4]\n",
      "Historial Usuario (en Train):  120955\n",
      "[ 1  6  4 33 52 50]\n",
      "50\n",
      "[ 1  6  4 33 52]\n",
      "Historial Usuario (en test):  33352\n",
      "[ 1  4 12 49  6  3]\n",
      "3\n",
      "[ 1  4 12 49  6]\n",
      "Historial Usuario (en test):  39070\n",
      "[ 1  4 44  3 40 36 41 50 52 16  6 33]\n",
      "33\n",
      "[ 1  4 44  3 40 36 41 50 52 16  6]\n",
      "Historial Usuario (en test):  29707\n",
      "[ 1 33  6 40 44  4 36 47 14 41 45  3]\n",
      "3\n",
      "[ 1 33  6 40 44  4 36 47 14 41 45]\n"
     ]
    }
   ],
   "source": [
    "Validusers= df2500_0.ID_Customer.unique()\n",
    "for i in np.random.choice(np.arange(len(X_train)), size=3):\n",
    "    print 'Historial Usuario (en Train): ', i\n",
    "    print X_train[i]\n",
    "    print y_train[i]\n",
    "    print X_traindel[i]\n",
    "for i in np.random.choice(np.arange(len(X_test)), size=3):\n",
    "    print 'Historial Usuario (en test): ', i\n",
    "    print X_train[i]\n",
    "    print y_train[i]\n",
    "    print X_traindel[i]\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are double sure that everything is ok. We have created the appropiate target and input.\n",
    "\n",
    "We shall now create the MLP model and fit it.\n",
    "\n",
    "First we shall explore our training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of product sequences:  403513\n",
      "Number of last objects: 403513\n"
     ]
    }
   ],
   "source": [
    "#Hacemos copia porque habra que jugar un poco\n",
    "X_train=np.copy(X_traindel)\n",
    "X_test=np.copy(X_testdel)\n",
    "print 'Number of product sequences: ', len(X_train)\n",
    "print 'Number of last objects:', y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean lenght:  5.09029696689 Std:  2.73919931406\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAAFdCAYAAADmEt9YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIPgA0AHBB4AOCD4AdEDwAaADgg8AHfh/X4y5l8ZvbCkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18910a9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sumarize sequence lenght\n",
    "size= map(len, X_train) #Applies function (len) to the sublists of X\n",
    "print 'Mean lenght: ', np.mean(size), 'Std: ', np.std(size)\n",
    "pyplot.boxplot(size)\n",
    "pyplot.ylim(ymax=15)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean is 5.096 products with a std of 2.73 products, the median is 5 products. It is clear that we can get the full purchase historic for most users for sequences with a fixed lenght of 6. (From 1-7)\n",
    "\n",
    "Let's start building our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "#Fix randome seed\n",
    "seed=7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Truncate or pad the sequences into maximum fixe lenght of 6\n",
    "max_products=6\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_products)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen= max_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1, 39, 38,  6, 16],\n",
       "       [ 0,  0,  1,  4,  6, 12],\n",
       "       [ 0,  6,  1, 39, 38,  4],\n",
       "       [ 0,  0,  1,  6,  4,  3],\n",
       "       [ 0,  0,  0,  0,  0,  4],\n",
       "       [ 1,  4, 52, 50, 33,  6],\n",
       "       [52, 50,  6,  4, 16, 33]], dtype=int32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(403513, 6)\n",
      "(100878, 6)\n",
      "[ 0  1 39 38  6 16]\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: \n",
      "(51,)\n",
      "(51,)\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "#Output classes, should be one less than original products. (ghost product)\n",
    "print 'Classes: '\n",
    "print np.unique(y_test).shape\n",
    "print np.unique(y_train).shape\n",
    "nclasses = np.unique(y_test).shape[0]\n",
    "print nclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:  53\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "top_product=np.max(X_train)+1\n",
    "print 'Vocabulary Size: ', top_product\n",
    "print np.max(df2500_0.Prod_int) #OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create the model:\n",
    "def base_model(top_product, vsdim , max_products, nclasses):\n",
    "    \"\"\"\n",
    "    Creamos un modelo, \n",
    "    max_products: input_lenght.\n",
    "    vsdim: defautl = 10 dimension del epsacio vectorial donde hcemos word embedding\n",
    "    top_product: Vocabulary size. Max label de los productos\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(top_product , vsdim, input_length=max_products))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(200,activation='relu'))\n",
    "    model.add(Dense(100, activation ='relu'))\n",
    "    model.add(Dense(nclasses+2, activation='sigmoid')) ## 0 and 1 where occupied by ghost. No time to fix this \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_5 (Embedding)          (None, 6, 5)          265         embedding_input_5[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 30)            0           embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 200)           6200        flatten_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 200)           40200       dense_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_19 (Dense)                 (None, 100)           20100       dense_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_20 (Dense)                 (None, 53)            5353        dense_19[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 72,118\n",
      "Trainable params: 72,118\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vsdim = 5 #Fijamos la dimension del espacio vectorial.\n",
    "model_0 = base_model(top_product, vsdim, max_products, nclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transformamos \n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_cat_train = to_categorical(y_train, nb_classes=None)\n",
    "y_cat_test = to_categorical(y_test, nb_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 51  3]\n",
      "52\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print y_train[:3]\n",
    "print np.max(y_train)\n",
    "print np.min(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two are the ghosts products, 'did not buy anything' and '1900 mark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print y_cat_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(403513, 53)\n",
      "(403513, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1, 39, 38,  6, 16],\n",
       "       [ 0,  0,  1,  4,  6, 12],\n",
       "       [ 0,  6,  1, 39, 38,  4]], dtype=int32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print y_cat_train.shape\n",
    "print X_train.shape\n",
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 51,  3])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 403513 samples, validate on 100878 samples\n",
      "Epoch 1/3\n",
      "403513/403513 [==============================] - 20s - loss: 2.0779 - acc: 0.3796 - val_loss: 1.8374 - val_acc: 0.4868\n",
      "Epoch 2/3\n",
      "403513/403513 [==============================] - 20s - loss: 1.8210 - acc: 0.4894 - val_loss: 1.8023 - val_acc: 0.4938\n",
      "Epoch 3/3\n",
      "403513/403513 [==============================] - 20s - loss: 1.7925 - acc: 0.4953 - val_loss: 1.7904 - val_acc: 0.4957\n",
      "Accuracy:  49.5737425406 %\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "\n",
    "model_0.fit(X_train, y_cat_train, validation_data=(X_test, y_cat_test), nb_epoch=3, batch_size=128, verbose=1)\n",
    "\n",
    "scores=model_0.evaluate(X_test, y_cat_test, verbose=0)\n",
    "\n",
    "print 'Accuracy: ', (scores[1]*100), '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
