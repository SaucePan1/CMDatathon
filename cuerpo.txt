Estimado Equipo Cajamar UniversityHack 2017,

Nuestro trabajo consiste en 3 notebooks de Python donde desarrollamos el análisis exploratorio de los datos mediante gráficos, cálculos de variables relevantes como número de productos o usuarios, histogramas, etc. (----Nombre del notebook1-----). En el notebook "LogisticRegression", hacemos una primera aproximación al problema mediante una regresión logística que considera como entradas los productos que ha comprado un usuario y sus características sociodemográficas para predecir cuál es el producto más probable que contrará a continuación. En el notebook (------Nombre del notebook3-------), consideramos una mejora al clasificador anterior, usando una red neuronal (multi layer perceptron).

En cuanto al análisis exploratorio, una vez familiarizados con los datos, hemos estudiado la distribución de los productos en función del número de compras para entender mejor el tipo de producto. En esta línea, hemos realizado gráficos por meses para inferir comportamientos periódicos y gráficos a lo largo de los años para ver la evolución de cada producto, con la intención de descubrir productos "obsoletos" o sin interés. Por otro lado, como existen entradas de hace 50 años, hemos visualizado la primera aparición de cada producto en la base de datos. Pues los clientes en 1980 tenían a su disposición productos diferentes de los actuales.

En cuanto a la manipulación de variables, hemos construido una tabla binaria con clientes y productos, de manera que si un cliente tenía un producto contratado, se le asignaba un uno a la celda correspodiente. A esta tabla se le han añadido las características sociodemográficas en formato one-hot encoding. Esto ha sido necesaria para entrenar la regresión logística, tambien la red neuronal.
 
Llegados a este punto hemos intentado subir el nivel de precision de nuestro modelo considerando el problema como si fuera un problema de lenguaje natural. En este caso solo hemos trabajado con el historial de compra de cada cliente y el orden concreto en que ha comprado los productos. Hemos llevado a cabo un ‘word embedding’ en un espacio vectorial de dimension 10. Este modelo esta compuesto de tres capas ‘hidden’ de 200, 200 y 100. En esta linea hemos hecho diferentes pruebas, eliminando los productos que tenían menos de 100, 300 y 2500 ventas totales, además hemos considerado la adición de una nueva variable que corresponde a la fecha 1990-01. Esto es porque a partir de esta fecha hay un incremento significativo de la cantidad de productos que ofrece cajamar, así que hemos considerado que los productos contratados antes y después de 1990 no tendrían porqué ser los mismos. También hemos explorado la opción de crear un modelo para cada clase de socio Socio_Demo_05. Ninguno de estas modificaciones a conducido a mejores resultados.


MLP_Socio_Demo.

En este caso, hemos hecho primero un filtraje de los productos menos vendidos, a cada ID_Customer le hemos asociado un ‘vector de compra’ de dimension igual al numero de productos considerados. És binario con 1 si ha comprado el producto en cuestión  y 0 si no. Ademàs a este vector le hemos añadido las características Socio_Demo de cada usuario ‘encoded’ a ‘one-hot’. El MLP consiste en una red neuronal con una entrada de dimensión 86, dos hidden layers de 200 neuronas con activation function ‘relu’. Por ultimo la salida es una capa de 86 dando la sequencia de productos final, incluyendo la predicción de el último producto. Haciendo una division de clientes entre ’train’ y ‘test’ para validar nuestra precisión. Hemos obtenido un resultado de precisión del 20%. Es por esto que hemos desechado el modelo.